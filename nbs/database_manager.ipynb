{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59c1b467",
   "metadata": {},
   "source": [
    "# DatabaseManager\n",
    "\n",
    "> This will be the interface between an application and the databse.  \n",
    "\n",
    "> In the immediate, it will initialise the database, read the Travel Advice JSON, ingest it via chunks into the database and it will perform searches given an embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81c3e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp DatabaseManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d03570",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pymilvus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857d23f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pymilvus\n",
    "\n",
    "from pymilvus import Collection, CollectionSchema, FieldSchema, DataType\n",
    "\n",
    "'''\n",
    "\n",
    "%pip install -qU \\\n",
    "  tiktoken==0.4.0 \\\n",
    "  openai==0.27.7 \\\n",
    "  langchain==0.0.179 \\\n",
    "  pinecone-client==2.2.1 \\\n",
    "  datasets==2.13.1 \\\n",
    "  cohere\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9c947e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d537b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DatabaseManager:\n",
    "    def __init__(self, config):\n",
    "        \"\"\"\n",
    "        Initialize the DatabaseManager with configuration settings.\n",
    "        :param config: Configuration details for database connection and other settings.\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        # Initialize database connection here\n",
    "\n",
    "\n",
    "\n",
    "    def chunk_json(self, json_data):\n",
    "        \"\"\"\n",
    "        Divide the JSON data into manageable chunks.\n",
    "        :param json_data: The parsed JSON data.\n",
    "        :return: List of chunks.\n",
    "        \"\"\"\n",
    "        # Implement chunking logic here\n",
    "        chunks = []\n",
    "        return chunks\n",
    "\n",
    "    def embed_chunks(self, chunks):\n",
    "        \"\"\"\n",
    "        Create embeddings for each chunk of data.\n",
    "        :param chunks: List of data chunks.\n",
    "        :return: List of embedded chunks.\n",
    "        \"\"\"\n",
    "        # Implement embedding logic here\n",
    "        embedded_chunks = []\n",
    "        return embedded_chunks\n",
    "\n",
    "    def initialize_database(self):\n",
    "        \"\"\"\n",
    "        Set up the Milvus database, including connection and schema.\n",
    "        \"\"\"\n",
    "        # Implement database initialization here\n",
    "\n",
    "    def store_in_milvus(self, embedded_chunks):\n",
    "        \"\"\"\n",
    "        Store embedded chunks in the Milvus database.\n",
    "        :param embedded_chunks: List of embedded chunks.\n",
    "        \"\"\"\n",
    "        # Implement storage logic here\n",
    "\n",
    "    def search_database(self, query, k):\n",
    "        \"\"\"\n",
    "        Search the database for K nearest chunks based on the query embedding.\n",
    "        :param query: Search query.\n",
    "        :param k: Number of nearest chunks to find.\n",
    "        :return: Search results.\n",
    "        \"\"\"\n",
    "        # Implement search logic here\n",
    "\n",
    "    def retrieve_data(self, search_results):\n",
    "        \"\"\"\n",
    "        Fetch chunk data and metadata based on search results.\n",
    "        :param search_results: Results from the database search.\n",
    "        :return: Corresponding data and metadata.\n",
    "        \"\"\"\n",
    "        # Implement data retrieval logic here\n",
    "\n",
    "    def __del__(self):\n",
    "        \"\"\"\n",
    "        Cleanup when an instance is destroyed, like closing database connections.\n",
    "        \"\"\"\n",
    "        # Implement cleanup logic here\n",
    "    \n",
    "    def ingest_json(self, file_path):\n",
    "        \"\"\"\n",
    "        Read and parse a JSON file.\n",
    "        :param file_path: Path to the JSON file.\n",
    "        :return: Parsed JSON data.\n",
    "        \"\"\"\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5294349",
   "metadata": {},
   "source": [
    "## Configure the database\n",
    "\n",
    "I'm not sure how we'll do it in the future.\n",
    "\n",
    "For time being, we are going to do two things now\n",
    "1. ingest the travel advice json\n",
    "2. turn that into a local database\n",
    "   \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0319b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'travel_file':  \"./ingest_data_sources/travel-advice-all-countries.json\"\n",
    "}\n",
    "\n",
    "db_manager = DatabaseManager(config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc18ae9",
   "metadata": {},
   "source": [
    "### Ingesting\n",
    "\n",
    "Here's what I'm doing\n",
    "\n",
    "1. We load the travel advice json into memory (data)\n",
    "2. We loop around it to turn it into a new structure that better fits our needs.\n",
    "\n",
    "   Each item will have this structure:\n",
    "   ```json\n",
    "   {\n",
    "       \"url\": \"/foreign-travel-advice/british-indian-ocean-territory\",\n",
    "       \"country_name\": \"British Indian Ocean Territory\",\n",
    "       \"content_title\": \"Summary\",\n",
    "       \"part_id\": 0,\n",
    "       \"content\": \"Before you travel, check the 'Entry requirements'....\",\n",
    "       \"content_html\": \"\\n<div class=\\\"example\\\">\\n<p>Before you travel, ...\"\n",
    "   }\n",
    "\n",
    "3. Note that for any individual country there are several \"parts\" - this is why we have so much metadata. It's so we can pull back each chunk.\n",
    "4.  We save the new formatted json as chunk_json_format.json in case we want to skip all this in the future - for time being, I'm assuming a 'dump' of this may change.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ab87a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = db_manager.ingest_json(db_manager.config['travel_file'])\n",
    "\n",
    "new_data_structure = []\n",
    "for element in data:\n",
    "    base_path = element[\"countryInfo\"][\"base_path\"]\n",
    "    country_name = element[\"countryInfo\"][\"details\"][\"country\"][\"name\"]\n",
    "    for index, part in enumerate(element[\"countryInfo\"][\"details\"][\"parts\"]):\n",
    "        html_content = part[\"body\"]\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        text_content = soup.get_text()\n",
    "\n",
    "        # Replace newlines and tabs with a space, and strip leading/trailing whitespaces\n",
    "        text_content = re.sub(r'\\s+', ' ', text_content).strip()\n",
    "\n",
    "        # Replace the Unicode characters I found with ASCII equivalents (maybe there are others)\n",
    "        replacements = {\n",
    "            '\\u2018': \"'\", '\\u2019': \"'\",  # Single quotes\n",
    "            '\\u201c': '\"', '\\u201d': '\"',  # Double quotes\n",
    "            '\\u2026': '...',               # Ellipsis (add anything else as required)\n",
    "        }\n",
    "        for unicode_char, ascii_char in replacements.items():\n",
    "            text_content = text_content.replace(unicode_char, ascii_char)\n",
    "\n",
    "        new_element = {\n",
    "            \"url\": base_path,\n",
    "            \"country_name\": country_name,\n",
    "            \"content_title\": part[\"title\"],\n",
    "            \"part_id\": index,\n",
    "            \"content\": text_content,\n",
    "            \"content_html\": html_content\n",
    "        }\n",
    "        new_data_structure.append(new_element)\n",
    "\n",
    "new_json_string = json.dumps(new_data_structure, indent=4)\n",
    "\n",
    "file_name = \"chunk_json_format.json\"\n",
    "with open(file_name, 'w', encoding='utf-8') as file:\n",
    "    file.write(new_json_string)\n",
    "\n",
    "#print(new_json_string[:5000])  # Adjust the slice as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4c1d7f",
   "metadata": {},
   "source": [
    "## Milvus Stuff\n",
    "\n",
    "1. Let's start by connecting to milvus and creating an appropritate collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225d2dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf51b473",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "connections.connect(\n",
    "  alias=\"default\",\n",
    "  user='username',\n",
    "  password='password',\n",
    "  host='127.0.0.1',\n",
    "  port='19530'\n",
    ")\n",
    "\n",
    "\n",
    "VECTOR_DIM = # [set the dimension of your vectors here]\n",
    "\n",
    "fields = [\n",
    "    FieldSchema(name=\"document_id\", dtype=DataType.INT64, is_primary=True, auto_id=False),\n",
    "    FieldSchema(name=\"content_vector\", dtype=DataType.FLOAT_VECTOR, dim=VECTOR_DIM)\n",
    "]\n",
    "\n",
    "schema = CollectionSchema(fields, description=\"Collection for document embeddings with metadata in JSON\")\n",
    "collection_name = \"your_document_collection\"\n",
    "document_collection = Collection(name=collection_name, schema=schema)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e31febc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer_name = tiktoken.encoding_for_model('gpt-4')\n",
    "tokenizer_name.name\n",
    "tokenizer = tiktoken.get_encoding(tokenizer_name.name)\n",
    "\n",
    "\n",
    "openai.api_key = openai_key\n",
    "if debug:\n",
    "  print (openai.Engine.list())  # check we have authenticated\n",
    "\n",
    "embed_model = \"text-embedding-ada-002\"\n",
    "\n",
    "res = openai.Embedding.create(\n",
    "    input=[\n",
    "        \"Sample document text goes here\",\n",
    "        \"there will be several phrases in each batch\"\n",
    "    ], engine=embed_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ee1d0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8371e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "connections.disconnect(\"default\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248caa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# Leave this to the bottom so we auto-export code\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cc5f26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9db2ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
